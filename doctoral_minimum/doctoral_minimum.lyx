#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage[T1]{fontenc}
% \usepackage{showframe}          % http://www.ctan.org/pkg/showframe
\usepackage[a4paper]{geometry}   % [a4paper]
\geometry{verbose,
	tmargin=1.9cm,
	bmargin=3.5cm,
	lmargin=2.7cm,
	rmargin=2.425cm,
	headheight=1.5cm,
	headsep=1cm,
	footskip=1.5cm}
\setcounter{secnumdepth}{3}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{setspace}
\usepackage[width=.75\textwidth]{caption}
\usepackage{enumitem}
\usepackage{float}
%\usepackage{algorithmic}
%\usepackage{algorithm}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{footmisc}
\usepackage{caption}
\let\counterwithout\relax
\let\counterwithin\relax
\usepackage{chngcntr}
\usepackage[english]{babel}
\usepackage{afterpage}
%\usepackage{float}
\usepackage{tikz}	% Drawing
\usepackage{tkz-euclide}
\usepackage{tikz-3dplot}
\usepackage{wrapfig}
\usepackage{xargs} % Use more than one optional parameter in a new commands
\usepackage{hyperref}
\usepackage{commath}
%\usepackage{subcaption} % subfigures
\usepackage{subfig} % to use subfloat
\usepackage{graphicx}
%\usepackage{fancyhdr} % fancy pagestyles
\usepackage{tabularx}
%\usepackage{showframe} % show page frames
%%\usepackage{biblatex}


\usepackage{multicol}  % multiple columns

%% Use Times New Roman font for text and Belleek font for math
%% Please make sure that the 'esint' package is turned off in the
%% 'Math options' page.
\usepackage[varg]{txfonts}

%% Use Utopia text with Fourier-GUTenberg math
%\usepackage{fourier}

%% Bitstream Charter text with Math Design math
%\usepackage[charter]{mathdesign}


%% Make the multiline figure/table captions indent so that the second
%% line "hangs" right below the first one.
%\usepackage[format=hang]{caption}

%% Indent even the first paragraph in each section
\usepackage{indentfirst}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date true
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Doctoral Minimum
\end_layout

\begin_layout Section
Motivation
\end_layout

\begin_layout Standard
The generalized aim of Natural Language Processing (NLP) is a decision making
 process given the contextual understanding.
 Over the last decade, the field made significant progress thanks to both
 spotlight attention of the commercial sector and many scientists and also
 to the immense investment and improvements in computational power.
 The current list of NLP tasks includes but is not limited to such problems
 like: topic classification
\begin_inset Note Note
status open

\begin_layout Plain Layout
ref
\end_layout

\end_inset

, machine translation
\begin_inset Note Note
status open

\begin_layout Plain Layout
ref
\end_layout

\end_inset

, named entity recognition
\begin_inset Note Note
status open

\begin_layout Plain Layout
ref
\end_layout

\end_inset

, language modeling
\begin_inset Note Note
status open

\begin_layout Plain Layout
ref
\end_layout

\end_inset

, coreference resolution
\begin_inset Note Note
status open

\begin_layout Plain Layout
ref
\end_layout

\end_inset

, etc..
 Astonishingly, a vast amount of task-specific solutions show almost human-like
 semantic understanding
\begin_inset Note Note
status open

\begin_layout Plain Layout
Question answering ref
\end_layout

\end_inset

 that brought even more attention to the field.
 The increased research activity resulted in a brain gain and a strong push
 of the boundaries in a majority of NLP problems, i.e representing language
 in a vector space
\begin_inset Note Note
status open

\begin_layout Plain Layout
Attention, etc.
\end_layout

\end_inset

.
 The newer and more complex models' architecture approaches, accompanied
 by the motto 
\begin_inset Quotes eld
\end_inset

the more parameters, the better
\begin_inset Quotes erd
\end_inset

, made the retraining more complicated and costly.
 However, the innovative fine tuning approaches present efficient solutions
 for the problem of the full retraining paradigm
\begin_inset Note Note
status open

\begin_layout Plain Layout
Ref
\end_layout

\end_inset

.
 The non arguable outcome of these improvements is an increase in the number
 of training instances i.e language models are usually trained with billions
 of text data
\begin_inset Note Note
status open

\begin_layout Plain Layout
60 billion articles dataset ref
\end_layout

\end_inset

.
 
\end_layout

\begin_layout Standard
Our research contribution lies in optimal models learning both from scratch
 or fine tuning of the pre-trained parameters.
 The training data collection is a highly time consuming and complicated
 procedure.
 In terms of supervised learning, the target labels acquisition is sometimes
 exceedingly expensive, e.g legal documents relevancy labeling
\begin_inset Note Note
status open

\begin_layout Plain Layout
ref
\end_layout

\end_inset

.
 The idea of the paper's methodology is to generalize the optimal learning
 and present its functionality regarding one of the most complex problems
 - coreference resolution.
 We simultaneously explore various correlated sectors such as i) active
 learning
\begin_inset Note Note
status open

\begin_layout Plain Layout
ref
\end_layout

\end_inset

, ii) models' uncertainty representation
\begin_inset Note Note
status open

\begin_layout Plain Layout
ref
\end_layout

\end_inset

 and iii) coreference resolution
\begin_inset Note Note
status open

\begin_layout Plain Layout
ref
\end_layout

\end_inset

.
 The topics of 
\shape italic
active learning
\shape default
 and 
\shape slanted
models uncertainty representation
\shape default
 are codependent.
 We propose a more granular study and extension of the human-machine communicati
on
\begin_inset Note Note
status open

\begin_layout Plain Layout
ref
\end_layout

\end_inset

.
 Among a huge quantity of unlabeled data the machine is expected to tell
 to an annotator (subject matter expert or so called oracle) which labels
 from the set of unlabeled data will bring forth the most information about
 the studied problem.
 Hence, the learning involves less data annotations and the model is trained
 with less effort.
 The following task is formulated as a supervised learning technique trained
 with the data obtained by the sequential labels querying from a human expert.
 This branch of research involves integration of enhanced models uncertainty
 measurement algorithms e.g deep ensembles
\begin_inset Note Note
status open

\begin_layout Plain Layout
[LPB16]
\end_layout

\end_inset

, MC Dropout
\begin_inset Note Note
status open

\begin_layout Plain Layout
[GIG17]
\end_layout

\end_inset

, SGLD
\begin_inset Note Note
status open

\begin_layout Plain Layout
[WT11]
\end_layout

\end_inset

 or Vadam
\begin_inset Note Note
status open

\begin_layout Plain Layout
[KNT+18]
\end_layout

\end_inset

 to the NLP problem for the empirical model weights distribution estimate.
 The additional information, given the distribution of predicted labels
 and the model prediction uncertainty
\begin_inset Note Note
status open

\begin_layout Plain Layout
[SSM21]
\end_layout

\end_inset

, allows for faster model learning (hot and warm start methods) with a lower
 number of training data.
 The architecture agnostic generalization of the empirical model weights
 distribution estimate will grant us more freedom in NLP models selection
 while preserving the precise insight into the model processes given prediction-
based uncertainty.
 The model uncertainty measurement and representation are done through the
 empirical estimate and sampling from the model weights distribution.
 The uncertainty representation approach provides the model with an expanded
 vision of both model learning and inference.
 The described technique has shown that such algorithms may enhance the
 learning process significantly
\begin_inset Note Note
status open

\begin_layout Plain Layout
[OFR+19]
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
The subsequent branch of this paper is the active learning and model uncertainty
 integration into the coreference resolution problem.
 Coreference resolution (CR) combines detection and linking various mentions
 of entities within the text: linking noun phrases with their counterparts
 and pronouns, anaphora disambiguation, linking words with their pro-forms,
 etc..
 Hence, CR-solving models significantly impact the quality of the text mining
 algorithms.
 The state-of-art CR models' architectures
\begin_inset Note Note
status open

\begin_layout Plain Layout
ref
\end_layout

\end_inset

 are not as massive as the language models and not as trivial as different
 NLP tasks.
 Thus, our inclination towards more complex neural network structures, tremendou
s requirements for context understanding, vast usage potential, and personal
 interest make this type of model the perfect candidate for uncertainty
 algorithms integration and improvement.
 A deeper insight into the models' decision making process given the uncertainty
 is expected to allow for a new coreference resolution state-of-art threshold
 to be set.
 
\end_layout

\begin_layout Standard
An exemplary use case where coreference resolution can be applied is categorizin
g entities and their pronouns to provide one with a broader spectrum of
 information for future decision making.
 Based on the extracted data, it is possible to unify all knowledge in the
 form of a Knowledge Graph (KG)
\begin_inset Note Note
status open

\begin_layout Plain Layout
[WMWG17]
\end_layout

\end_inset

 which can be further utilized for linking concepts represented by textual
 spans.
 Dependencies and connections between the entities can enrich the feature
 space with highly discriminative samples for other tasks.
 For example, assume that we have the following two consecutive sentences:
 "John Smith and Amanda Brown are accountants at XYZ company.
 Amanda’s colleague was accused of drunk driving".
 Based on these sentences, one would wish to classify if some of the entities
 from the text can be charged with a misdemeanor.
 For a human reader, it is evident that Amanda’s colleague refers to John.
 However, for a machine, that is a challenging task.
 Therefore, proper identification of entity clusters like John Smith, Amanda’s
 colleague, Amanda Brown, XYZ would significantly improve the machine’s
 understanding of the text.
 Another potential application of coreference resolution lies within the
 problem of opinion mining in media resources, where people frequently express
 their views and opinions.
 For example, heated discussions may emerge under political news articles.
 In these discussions, participants refer to subjects of the particular
 article with, for instance, pronouns.
 Therefore, proper CR may provide better traction of the audience’s attitude
 towards entities from the article by linking comment mentions to them.
\end_layout

\end_body
\end_document
